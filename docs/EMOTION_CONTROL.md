# TTS æƒ…æ„Ÿæ§åˆ¶æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

ç”±æ–¼ Coqui Studio çš„ `emotion` åƒæ•¸å·²è¢«æ£„ç”¨ï¼Œæˆ‘å€‘ä½¿ç”¨ **Voice Cloningï¼ˆè²éŸ³å…‹éš†ï¼‰** æŠ€è¡“ä¾†æ§åˆ¶ TTS çš„æƒ…æ„Ÿå’Œèªæ°£ã€‚

## ğŸ­ å·¥ä½œåŸç†

é€šéæä¾›å¸¶æœ‰ç‰¹å®šæƒ…æ„Ÿçš„**åƒè€ƒéŸ³è¨Š**ï¼ŒXTTS æ¨¡å‹æœƒæ¨¡ä»¿è©²éŸ³è¨Šçš„ï¼š
- ğŸµ **èªèª¿**ï¼ˆtoneï¼‰
- ğŸ¤ **èªé€Ÿ**ï¼ˆspeedï¼‰
- ğŸ’¬ **èªªè©±é¢¨æ ¼**ï¼ˆstyleï¼‰
- ğŸ˜Š **æƒ…æ„Ÿ**ï¼ˆemotionï¼‰

## ğŸ“ æº–å‚™æƒ…æ„Ÿåƒè€ƒéŸ³è¨Š

### 1. å‰µå»ºæƒ…æ„ŸéŸ³è¨Šç›®éŒ„

```bash
mkdir -p resource/emotions
```

### 2. æº–å‚™ä¸åŒæƒ…æ„Ÿçš„åƒè€ƒéŸ³è¨Š

æ¯å€‹æƒ…æ„Ÿæº–å‚™ä¸€å€‹ 5-30 ç§’çš„ WAV éŸ³è¨Šæª”æ¡ˆï¼š

```
resource/emotions/
â”œâ”€â”€ happy.wav       # é–‹å¿ƒ/æ„‰å¿«çš„èªæ°£
â”œâ”€â”€ sad.wav         # æ‚²å‚·/ä½è½çš„èªæ°£
â”œâ”€â”€ angry.wav       # ç”Ÿæ°£/æ¿€å‹•çš„èªæ°£
â”œâ”€â”€ neutral.wav     # ä¸­æ€§/å¹³éœçš„èªæ°£
â”œâ”€â”€ excited.wav     # èˆˆå¥®/ç†±æƒ…çš„èªæ°£
â”œâ”€â”€ gentle.wav      # æº«æŸ”/æŸ”å’Œçš„èªæ°£
â””â”€â”€ professional.wav # å°ˆæ¥­/æ­£å¼çš„èªæ°£
```

### 3. éŸ³è¨Šè¦æ±‚

âœ… **æ ¼å¼**: WAVï¼ˆ16-bit PCMï¼‰  
âœ… **æ¡æ¨£ç‡**: 22050 Hz æˆ–æ›´é«˜  
âœ… **æ™‚é•·**: 5-30 ç§’ï¼ˆ10 ç§’å·¦å³æœ€ä½³ï¼‰  
âœ… **å…§å®¹**: æ¸…æ™°çš„äººè²ï¼Œæœ€å¥½æ˜¯ä¸­æ–‡  
âœ… **è³ªé‡**: ç„¡å™ªéŸ³ã€ç„¡èƒŒæ™¯éŸ³æ¨‚

## ğŸ”§ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³• 1ï¼šä½¿ç”¨ç’°å¢ƒè®Šæ•¸ï¼ˆå…¨åŸŸè¨­å®šï¼‰

åœ¨ `.env` ä¸­è¨­å®šé è¨­çš„åƒè€ƒéŸ³è¨Šï¼š

```bash
# é è¨­ä½¿ç”¨çš„æƒ…æ„ŸéŸ³è¨Š
TTS_SPEAKER_WAV=resource/emotions/neutral.wav

# æƒ…æ„ŸéŸ³è¨Šç›®éŒ„
EMOTION_AUDIO_DIR=resource/emotions
```

### æ–¹æ³• 2ï¼šä½¿ç”¨ EmotionManagerï¼ˆå‹•æ…‹åˆ‡æ›ï¼‰

```python
from modules.utils.emotion_manager import EmotionManager

# åˆå§‹åŒ–æƒ…æ„Ÿç®¡ç†å™¨
emotion_mgr = EmotionManager()

# åˆ—å‡ºå¯ç”¨æƒ…æ„Ÿ
print(emotion_mgr.list_emotions())
# è¼¸å‡º: ['happy', 'sad', 'angry', 'neutral', 'excited', 'gentle', 'professional']

# å–å¾—ç‰¹å®šæƒ…æ„Ÿçš„éŸ³è¨Šè·¯å¾‘
happy_audio = emotion_mgr.get_emotion_audio("happy")

# ä½¿ç”¨å¸¶æƒ…æ„Ÿçš„ TTS
tts_result = tts_engine.synthesize(
    text="ä»Šå¤©å¤©æ°£çœŸå¥½ï¼",
    language="zh-cn",
    speaker_wav=happy_audio  # ä½¿ç”¨é–‹å¿ƒçš„èªæ°£
)
```

### æ–¹æ³• 3ï¼šæ•´åˆåˆ° VoiceAgent

ä¿®æ”¹ `modules/agent.py`ï¼Œè®“ Agent æ ¹æ“šå°è©±å…§å®¹è‡ªå‹•é¸æ“‡æƒ…æ„Ÿï¼š

```python
from modules.utils.emotion_manager import get_emotion_manager

class VoiceAgent:
    def __init__(self, ...):
        # ...
        self.emotion_mgr = get_emotion_manager()
    
    def _detect_emotion(self, text: str) -> str:
        """ç°¡å–®çš„æƒ…æ„Ÿæª¢æ¸¬ï¼ˆå¯ä»¥æ›´è¤‡é›œï¼‰ã€‚"""
        text_lower = text.lower()
        
        if any(word in text_lower for word in ["é–‹å¿ƒ", "é«˜èˆˆ", "å“ˆå“ˆ", "ğŸ˜Š", "å¤ªå¥½äº†"]):
            return "happy"
        elif any(word in text_lower for word in ["é›£é", "å‚·å¿ƒ", "ğŸ˜¢", "éºæ†¾"]):
            return "sad"
        elif any(word in text_lower for word in ["ç”Ÿæ°£", "æ†¤æ€’", "ğŸ˜ ", "å¯æƒ¡"]):
            return "angry"
        else:
            return "neutral"
    
    def synthesize_with_emotion(self, text: str, language: str = None):
        """å¸¶æƒ…æ„Ÿçš„ TTS åˆæˆã€‚"""
        # æª¢æ¸¬æƒ…æ„Ÿ
        emotion = self._detect_emotion(text)
        
        # å–å¾—å°æ‡‰çš„åƒè€ƒéŸ³è¨Š
        speaker_wav = self.emotion_mgr.get_emotion_audio(emotion)
        
        # åˆæˆ
        return self.tts.synthesize(
            text=text,
            language=language,
            speaker_wav=speaker_wav
        )
```

## ğŸ¯ å¯¦ç”¨ç¯„ä¾‹

### ç¯„ä¾‹ 1ï¼šæ ¹æ“šå ´æ™¯åˆ‡æ›æƒ…æ„Ÿ

```python
# æ­¡è¿èª - ä½¿ç”¨å‹å–„çš„èªæ°£
greeting = tts_engine.synthesize(
    text="æ‚¨å¥½ï¼æ­¡è¿ä½¿ç”¨èªéŸ³åŠ©ç†ï¼",
    speaker_wav="resource/emotions/gentle.wav"
)

# éŒ¯èª¤æç¤º - ä½¿ç”¨æ­£å¼çš„èªæ°£
error = tts_engine.synthesize(
    text="æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ã€‚",
    speaker_wav="resource/emotions/professional.wav"
)

# æˆåŠŸå›é¥‹ - ä½¿ç”¨é–‹å¿ƒçš„èªæ°£
success = tts_engine.synthesize(
    text="å¤ªå¥½äº†ï¼å·²ç¶“å¹«æ‚¨å®Œæˆäº†ï¼",
    speaker_wav="resource/emotions/happy.wav"
)
```

### ç¯„ä¾‹ 2ï¼šLLM æ§åˆ¶æƒ…æ„Ÿ

è®“ LLM åœ¨å›æ‡‰ä¸­æŒ‡å®šæƒ…æ„Ÿæ¨™è¨˜ï¼š

```python
# LLM System Prompt
system_prompt = """
ä½ æ˜¯ä¸€å€‹å‹å–„çš„åŠ©ç†ã€‚
åœ¨å›æ‡‰çš„é–‹é ­ç”¨ [EMOTION:xxx] æ¨™è¨˜ä¾†æŒ‡å®šèªæ°£ï¼Œä¾‹å¦‚ï¼š
- [EMOTION:happy] è¡¨ç¤ºé–‹å¿ƒ
- [EMOTION:sad] è¡¨ç¤ºåŒæƒ…
- [EMOTION:neutral] è¡¨ç¤ºä¸­æ€§
"""

# è§£æ LLM å›æ‡‰
response = "[EMOTION:happy] çœŸé«˜èˆˆèƒ½å¹«åˆ°ä½ ï¼ä»Šå¤©å¤©æ°£çœŸå¥½ï¼"

# æå–æƒ…æ„Ÿæ¨™è¨˜
import re
match = re.match(r'\[EMOTION:(\w+)\](.*)', response)
if match:
    emotion = match.group(1)
    text = match.group(2).strip()
    
    # ä½¿ç”¨å°æ‡‰æƒ…æ„Ÿåˆæˆ
    speaker_wav = emotion_mgr.get_emotion_audio(emotion)
    tts_result = tts_engine.synthesize(text, speaker_wav=speaker_wav)
```

## ğŸ¬ è£½ä½œåƒè€ƒéŸ³è¨Šçš„æŠ€å·§

### ä½¿ç”¨ Text-to-Speech ç”Ÿæˆ

å¦‚æœæ²’æœ‰çœŸäººéŒ„éŸ³ï¼Œå¯ä»¥ç”¨é«˜è³ªé‡ TTS ç”Ÿæˆï¼š

```python
from TTS.api import TTS

# ä½¿ç”¨é«˜è³ªé‡æ¨¡å‹ç”Ÿæˆåƒè€ƒéŸ³è¨Š
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")

# ç”Ÿæˆä¸åŒæƒ…æ„Ÿçš„éŸ³è¨Šï¼ˆéœ€è¦äººå·¥èª¿æ•´æ–‡æœ¬ä»¥è¡¨é”æƒ…æ„Ÿï¼‰
tts.tts_to_file(
    text="ä»Šå¤©çœŸæ˜¯å¤ªé–‹å¿ƒäº†ï¼ä¸€åˆ‡éƒ½å¾ˆé †åˆ©ï¼",
    language="zh-cn",
    file_path="resource/emotions/happy.wav"
)

tts.tts_to_file(
    text="é€™ä»¶äº‹è®“æˆ‘æ„Ÿåˆ°å¾ˆé›£éã€‚å¸Œæœ›èƒ½å¤ æ”¹å–„ã€‚",
    language="zh-cn", 
    file_path="resource/emotions/sad.wav"
)
```

### å¾å½±ç‰‡/éŸ³è¨Šæå–

```bash
# ä½¿ç”¨ FFmpeg æå–ä¸¦è½‰æ›æ ¼å¼
ffmpeg -i input_video.mp4 -ss 00:01:30 -t 00:00:10 \
       -ar 22050 -ac 1 resource/emotions/happy.wav
```

## âš™ï¸ é€²éšé…ç½®

### èª¿æ•´åƒè€ƒéŸ³è¨Šçš„å½±éŸ¿ç¨‹åº¦

æŸäº› TTS æ¨¡å‹æ”¯æ´èª¿æ•´å…‹éš†å¼·åº¦ï¼ˆéœ€æŸ¥çœ‹æ¨¡å‹æ–‡æª”ï¼‰ï¼š

```python
# éƒ¨åˆ†æ¨¡å‹æ”¯æ´çš„åƒæ•¸ï¼ˆè¦–æ¨¡å‹è€Œå®šï¼‰
tts.tts(
    text="æ¸¬è©¦æ–‡æœ¬",
    speaker_wav="reference.wav",
    temperature=0.7,  # æ§åˆ¶å‰µé€ æ€§
    # å…¶ä»–å¯èƒ½çš„åƒæ•¸...
)
```

## ğŸ” æ•…éšœæ’é™¤

### å•é¡Œï¼šæƒ…æ„Ÿä¸æ˜é¡¯

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨æ›´é•·çš„åƒè€ƒéŸ³è¨Šï¼ˆ10-15 ç§’ï¼‰
2. ç¢ºä¿åƒè€ƒéŸ³è¨Šçš„æƒ…æ„Ÿè¡¨é”æ˜ç¢º
3. ä½¿ç”¨æ›´é«˜è³ªé‡çš„åƒè€ƒéŸ³è¨Š

### å•é¡Œï¼šåƒè€ƒéŸ³è¨Šç„¡æ•ˆ

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```python
# æª¢æŸ¥éŸ³è¨Šæª”æ¡ˆ
from pathlib import Path
import librosa

audio_path = "resource/emotions/happy.wav"
if Path(audio_path).is_file():
    # è¼‰å…¥ä¸¦æª¢æŸ¥
    y, sr = librosa.load(audio_path)
    duration = librosa.get_duration(y=y, sr=sr)
    print(f"éŸ³è¨Šæ™‚é•·: {duration:.2f} ç§’")
    print(f"æ¡æ¨£ç‡: {sr} Hz")
else:
    print(f"æª”æ¡ˆä¸å­˜åœ¨: {audio_path}")
```

## ğŸ“š ç›¸é—œè³‡æº

- [XTTS æ–‡æª”](https://github.com/coqui-ai/TTS)
- [Voice Cloning æœ€ä½³å¯¦è¸](https://docs.coqui.ai/en/latest/tutorial_for_nervous_beginners.html)
