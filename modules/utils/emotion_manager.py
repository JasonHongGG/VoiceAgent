"""æƒ…æ„ŸéŸ³è¨Šç®¡ç†å™¨ - ç”¨æ–¼æ§åˆ¶ TTS çš„æƒ…æ„Ÿå’Œèªæ°£ã€‚"""

import os
import re
from pathlib import Path
from typing import Optional, Dict, Any


class EmotionManager:
    """
    ç®¡ç†ä¸åŒæƒ…æ„Ÿçš„åƒè€ƒéŸ³è¨Šå’Œ TTS åƒæ•¸ï¼Œç”¨æ–¼ TTS æƒ…æ„Ÿæ§åˆ¶ã€‚
    
    é€šéä½¿ç”¨ä¸åŒæƒ…æ„Ÿçš„åƒè€ƒéŸ³è¨Šå’Œåƒæ•¸é…ç½®ï¼Œå¯ä»¥è®“ TTS ç”Ÿæˆç›¸æ‡‰æƒ…æ„Ÿçš„èªéŸ³ã€‚
    æ”¯æ´å…©ç¨®æ§åˆ¶æ–¹å¼ï¼š
    1. åƒè€ƒéŸ³è¨Š (speaker_wav) - æ§åˆ¶åŸºç¤éŸ³è‰²å’Œé¢¨æ ¼
    2. åƒæ•¸èª¿æ•´ (temperature, speed ç­‰) - å¾®èª¿æƒ…æ„Ÿè¡¨é”
    """
    
    # é è¨­çš„æƒ…æ„Ÿåƒæ•¸é…ç½®
    DEFAULT_EMOTION_PARAMS = {
        "neutral": {
            "temperature": 0.4,
            "speed": 1.0,
            "repetition_penalty": 12.0,
            "top_p": 0.75,
        },
        "happy": {
            "temperature": 1.0,
            "speed": 1.1,
            "repetition_penalty": 8.0,
            "top_p": 0.9,
        },
        "excited": {
            "temperature": 1.1,
            "speed": 1.2,
            "repetition_penalty": 8.0,
            "top_p": 0.9,
        },
        "sad": {
            "temperature": 0.7,
            "speed": 0.85,
            "repetition_penalty": 12.0,
            "top_p": 0.8,
        },
        "angry": {
            "temperature": 0.9,
            "speed": 1.15,
            "repetition_penalty": 10.0,
            "top_p": 0.85,
        },
        "gentle": {
            "temperature": 0.65,
            "speed": 0.9,
            "repetition_penalty": 11.0,
            "top_p": 0.8,
        },
        "professional": {
            "temperature": 0.5,
            "speed": 0.95,
            "repetition_penalty": 15.0,
            "top_p": 0.75,
        },
    }
    
    def __init__(self, emotion_audio_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–æƒ…æ„Ÿç®¡ç†å™¨ã€‚
        
        Args:
            emotion_audio_dir: å­˜æ”¾æƒ…æ„Ÿåƒè€ƒéŸ³è¨Šçš„ç›®éŒ„è·¯å¾‘
        """
        self.emotion_audio_dir = emotion_audio_dir or os.getenv("EMOTION_AUDIO_DIR", "resource/emotions")
        self.emotion_map: Dict[str, str] = {}
        
        # è¼‰å…¥æƒ…æ„ŸéŸ³è¨Šæ˜ å°„
        self._load_emotion_map()
    
    def _load_emotion_map(self):
        """å¾ç›®éŒ„è¼‰å…¥æƒ…æ„ŸéŸ³è¨Šæ˜ å°„ã€‚"""
        emotion_dir = Path(self.emotion_audio_dir)
        
        if not emotion_dir.exists():
            print(f"[EmotionManager] Emotion directory '{self.emotion_audio_dir}' not found, creating...")
            emotion_dir.mkdir(parents=True, exist_ok=True)
            return
        
        # æƒæç›®éŒ„ä¸­çš„ .wav æª”æ¡ˆ
        for audio_file in emotion_dir.glob("*.wav"):
            # ä½¿ç”¨æª”åï¼ˆä¸å«å‰¯æª”åï¼‰ä½œç‚ºæƒ…æ„Ÿåç¨±
            emotion_name = audio_file.stem.lower()
            self.emotion_map[emotion_name] = str(audio_file)
            print(f"[EmotionManager] Loaded emotion '{emotion_name}': {audio_file}")
        
        if not self.emotion_map:
            print(f"[EmotionManager] No emotion audio files found in '{self.emotion_audio_dir}'")
    
    def detect_emotion_from_text(self, text: str) -> str:
        """
        å¾æ–‡å­—å…§å®¹è‡ªå‹•åµæ¸¬æƒ…æ„Ÿã€‚
        
        Args:
            text: è¼¸å…¥æ–‡å­—
            
        Returns:
            åµæ¸¬åˆ°çš„æƒ…æ„Ÿåç¨±ï¼ˆå¦‚æœç„¡æ³•åˆ¤æ–·å‰‡è¿”å› "neutral"ï¼‰
        """
        text = text.lower()
        
        # ç°¡å–®çš„é—œéµå­—åŒ¹é…ï¼ˆå¯ä»¥æ ¹æ“šéœ€æ±‚æ“´å±•ï¼‰
        emotion_keywords = {
            "happy": ["é–‹å¿ƒ", "å¿«æ¨‚", "å¤ªå¥½äº†", "å¤ªæ£’äº†", "å“ˆå“ˆ", "ğŸ˜Š", "ğŸ˜„", "ğŸ‰"],
            "excited": ["èˆˆå¥®", "æ¿€å‹•", "é©šå–œ", "å“‡", "ğŸ˜", "ğŸ¤©"],
            "sad": ["é›£é", "å‚·å¿ƒ", "éºæ†¾", "å¯æƒœ", "ğŸ˜¢", "ğŸ˜­"],
            "angry": ["ç”Ÿæ°£", "æ†¤æ€’", "å¯æƒ¡", "ğŸ˜ ", "ğŸ˜¡"],
            "gentle": ["æº«æŸ”", "è¼•è²", "åˆ¥æ“”å¿ƒ", "æ²’é—œä¿‚", "å®‰æ…°"],
            "professional": ["å ±å‘Š", "æ•¸æ“š", "åˆ†æ", "æ ¹æ“š", "é¡¯ç¤º"],
        }
        
        # æª¢æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æƒ…æ„Ÿé—œéµå­—
        for emotion, keywords in emotion_keywords.items():
            for keyword in keywords:
                if keyword in text:
                    print(f"[EmotionManager] Detected emotion '{emotion}' from keyword '{keyword}'")
                    return emotion
        
        # é è¨­è¿”å›ä¸­æ€§
        return "neutral"
    
    def get_emotion_config(
        self,
        emotion: Optional[str] = None,
        text: Optional[str] = None,
        auto_detect: bool = True,
    ) -> Dict[str, Any]:
        """
        å–å¾—æƒ…æ„Ÿçš„å®Œæ•´é…ç½®ï¼ˆåƒè€ƒéŸ³è¨Š + TTS åƒæ•¸ï¼‰ã€‚
        
        Args:
            emotion: æŒ‡å®šçš„æƒ…æ„Ÿåç¨±
            text: æ–‡å­—å…§å®¹ï¼ˆç”¨æ–¼è‡ªå‹•åµæ¸¬æƒ…æ„Ÿï¼‰
            auto_detect: æ˜¯å¦è‡ªå‹•åµæ¸¬æƒ…æ„Ÿ
            
        Returns:
            åŒ…å« speaker_wav å’Œ TTS åƒæ•¸çš„å­—å…¸
        """
        # 1. æ±ºå®šä½¿ç”¨å“ªç¨®æƒ…æ„Ÿ
        final_emotion = None
        
        if emotion:
            # å„ªå…ˆä½¿ç”¨æŒ‡å®šçš„æƒ…æ„Ÿ
            final_emotion = emotion.lower()
        elif auto_detect and text:
            # å¾æ–‡å­—è‡ªå‹•åµæ¸¬
            final_emotion = self.detect_emotion_from_text(text)
        else:
            # é è¨­ä½¿ç”¨ä¸­æ€§
            final_emotion = "neutral"
        
        print(f"[EmotionManager] Using emotion: {final_emotion}")
        
        # 2. æº–å‚™é…ç½®
        config = {}
        
        # 2.1 åŠ å…¥åƒè€ƒéŸ³è¨Šï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        speaker_wav = self.get_emotion_audio(final_emotion)
        if speaker_wav:
            config["speaker_wav"] = speaker_wav
        
        # 2.2 åŠ å…¥ TTS åƒæ•¸
        emotion_params = self.DEFAULT_EMOTION_PARAMS.get(
            final_emotion,
            self.DEFAULT_EMOTION_PARAMS["neutral"]
        )
        config.update(emotion_params)
        
        return config
    
    def get_emotion_audio(self, emotion: str) -> Optional[str]:
        """
        å–å¾—æŒ‡å®šæƒ…æ„Ÿçš„åƒè€ƒéŸ³è¨Šè·¯å¾‘ã€‚
        
        Args:
            emotion: æƒ…æ„Ÿåç¨±ï¼ˆå¦‚ "happy", "sad", "angry", "neutral" ç­‰ï¼‰
            
        Returns:
            åƒè€ƒéŸ³è¨Šçš„æª”æ¡ˆè·¯å¾‘ï¼Œå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å› None
        """
        emotion = emotion.lower()
        audio_path = self.emotion_map.get(emotion)
        
        if audio_path:
            print(f"[EmotionManager] Selected emotion '{emotion}': {audio_path}")
        else:
            print(f"[EmotionManager] Emotion '{emotion}' not found. Available: {list(self.emotion_map.keys())}")
        
        return audio_path
    
    def list_emotions(self) -> list[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æƒ…æ„Ÿã€‚"""
        return list(self.emotion_map.keys())
    
    def add_emotion(self, emotion: str, audio_path: str):
        """
        æ‰‹å‹•æ·»åŠ æƒ…æ„ŸéŸ³è¨Šæ˜ å°„ã€‚
        
        Args:
            emotion: æƒ…æ„Ÿåç¨±
            audio_path: éŸ³è¨Šæª”æ¡ˆè·¯å¾‘
        """
        if not Path(audio_path).is_file():
            raise FileNotFoundError(f"Audio file not found: {audio_path}")
        
        self.emotion_map[emotion.lower()] = audio_path
        print(f"[EmotionManager] Added emotion '{emotion}': {audio_path}")


# å…¨åŸŸæƒ…æ„Ÿç®¡ç†å™¨å¯¦ä¾‹ï¼ˆå¯é¸ï¼‰
_global_emotion_manager = None


def get_emotion_manager() -> EmotionManager:
    """å–å¾—å…¨åŸŸæƒ…æ„Ÿç®¡ç†å™¨å¯¦ä¾‹ã€‚"""
    global _global_emotion_manager
    if _global_emotion_manager is None:
        _global_emotion_manager = EmotionManager()
    return _global_emotion_manager
