"""æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æƒ…æ„Ÿæ§åˆ¶ TTSã€‚"""

import os
from dotenv import load_dotenv

from modules.tts import CoquiTTS
from modules.utils.emotion_manager import EmotionManager

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def demo_basic_emotion_control():
    """åŸºæœ¬çš„æƒ…æ„Ÿæ§åˆ¶æ¼”ç¤ºã€‚"""
    print("="*60)
    print("æ¼”ç¤º 1: åŸºæœ¬æƒ…æ„Ÿæ§åˆ¶")
    print("="*60)
    
    # åˆå§‹åŒ– TTS
    tts = CoquiTTS()
    
    # åˆå§‹åŒ–æƒ…æ„Ÿç®¡ç†å™¨
    emotion_mgr = EmotionManager()
    
    # åˆ—å‡ºå¯ç”¨æƒ…æ„Ÿ
    print(f"\nå¯ç”¨æƒ…æ„Ÿ: {emotion_mgr.list_emotions()}")
    
    # æ¸¬è©¦ä¸åŒæƒ…æ„Ÿ
    test_cases = [
        ("neutral", "æ‚¨å¥½ï¼Œæˆ‘æ˜¯èªéŸ³åŠ©ç†ã€‚"),
        ("happy", "å¤ªå¥½äº†ï¼ä»Šå¤©å¤©æ°£çœŸæ£’ï¼"),
        ("sad", "å¾ˆæŠ±æ­‰è½åˆ°é€™å€‹æ¶ˆæ¯ã€‚"),
        ("professional", "è«‹å•æœ‰ä»€éº¼å¯ä»¥å¹«åŠ©æ‚¨çš„ï¼Ÿ"),
    ]
    
    for emotion, text in test_cases:
        print(f"\n--- æ¸¬è©¦æƒ…æ„Ÿ: {emotion} ---")
        print(f"æ–‡æœ¬: {text}")
        
        # å–å¾—æƒ…æ„ŸéŸ³è¨Š
        speaker_wav = emotion_mgr.get_emotion_audio(emotion)
        
        if speaker_wav:
            # åˆæˆ
            result = tts.synthesize(
                text=text,
                language="zh-cn",
                speaker_wav=speaker_wav
            )
            print(f"âœ“ åˆæˆæˆåŠŸ: {len(result.audio)} æ¨£æœ¬")
            # é€™è£¡å¯ä»¥æ’­æ”¾æˆ–å„²å­˜éŸ³è¨Š
        else:
            print(f"âœ— æ‰¾ä¸åˆ°æƒ…æ„ŸéŸ³è¨Šæª”æ¡ˆ")


def demo_emotion_detection():
    """è‡ªå‹•æƒ…æ„Ÿæª¢æ¸¬æ¼”ç¤ºã€‚"""
    print("\n" + "="*60)
    print("æ¼”ç¤º 2: è‡ªå‹•æƒ…æ„Ÿæª¢æ¸¬")
    print("="*60)
    
    def detect_emotion(text: str) -> str:
        """ç°¡å–®çš„æƒ…æ„Ÿæª¢æ¸¬ã€‚"""
        text_lower = text.lower()
        
        if any(word in text_lower for word in ["é–‹å¿ƒ", "é«˜èˆˆ", "å“ˆå“ˆ", "å¤ªå¥½äº†", "æ£’"]):
            return "happy"
        elif any(word in text_lower for word in ["é›£é", "å‚·å¿ƒ", "éºæ†¾", "æŠ±æ­‰"]):
            return "sad"
        elif any(word in text_lower for word in ["è«‹å•", "æ‚¨å¥½", "å¹«åŠ©"]):
            return "professional"
        else:
            return "neutral"
    
    # æ¸¬è©¦æ–‡æœ¬
    test_texts = [
        "æ‚¨å¥½ï¼è«‹å•æœ‰ä»€éº¼å¯ä»¥å¹«åŠ©æ‚¨çš„ï¼Ÿ",
        "å¤ªå¥½äº†ï¼æ‚¨çš„è¨‚å–®å·²ç¶“æˆåŠŸæäº¤ï¼",
        "å¾ˆæŠ±æ­‰ï¼Œç³»çµ±ç›®å‰ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ã€‚",
        "ä»Šå¤©å¤©æ°£å¦‚ä½•ï¼Ÿ",
    ]
    
    tts = CoquiTTS()
    emotion_mgr = EmotionManager()
    
    for text in test_texts:
        # æª¢æ¸¬æƒ…æ„Ÿ
        emotion = detect_emotion(text)
        print(f"\næ–‡æœ¬: {text}")
        print(f"æª¢æ¸¬åˆ°çš„æƒ…æ„Ÿ: {emotion}")
        
        # å–å¾—å°æ‡‰éŸ³è¨Š
        speaker_wav = emotion_mgr.get_emotion_audio(emotion)
        
        if speaker_wav:
            result = tts.synthesize(
                text=text,
                language="zh-cn",
                speaker_wav=speaker_wav
            )
            print(f"âœ“ ä½¿ç”¨ {emotion} æƒ…æ„ŸåˆæˆæˆåŠŸ")


def demo_create_emotion_audio():
    """æ¼”ç¤ºå¦‚ä½•å‰µå»ºæƒ…æ„Ÿåƒè€ƒéŸ³è¨Šã€‚"""
    print("\n" + "="*60)
    print("æ¼”ç¤º 3: å‰µå»ºæƒ…æ„Ÿåƒè€ƒéŸ³è¨Š")
    print("="*60)
    
    from TTS.api import TTS
    from pathlib import Path
    
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    emotion_dir = Path("resource/emotions")
    emotion_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆå§‹åŒ– TTS
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to("cuda")
    
    # ä¸åŒæƒ…æ„Ÿçš„ç¤ºç¯„æ–‡æœ¬ï¼ˆéœ€è¦è¡¨é”å‡ºå°æ‡‰æƒ…æ„Ÿï¼‰
    emotion_texts = {
        "happy": "ä»Šå¤©çœŸæ˜¯å¤ªé–‹å¿ƒäº†ï¼ä¸€åˆ‡éƒ½å¾ˆé †åˆ©ï¼Œè®“äººæ„Ÿåˆ°éå¸¸æ„‰å¿«ï¼",
        "sad": "é€™ä»¶äº‹è®“æˆ‘æ„Ÿåˆ°å¾ˆé›£éã€‚çœŸå¸Œæœ›æƒ…æ³èƒ½å¤ æ”¹å–„ã€‚",
        "neutral": "é€™æ˜¯ä¸€æ®µå¹³éœã€ä¸­æ€§çš„æ•˜è¿°ã€‚æ²’æœ‰ç‰¹åˆ¥çš„æƒ…ç·’èµ·ä¼ã€‚",
        "professional": "æ­¡è¿è‡´é›»å®¢æœä¸­å¿ƒã€‚è«‹å•æœ‰ä»€éº¼å¯ä»¥ç‚ºæ‚¨æœå‹™çš„ï¼Ÿ",
        "excited": "å“‡ï¼é€™çœŸæ˜¯å¤ªæ£’äº†ï¼æˆ‘ç­‰ä¸åŠè¦é–‹å§‹äº†ï¼",
    }
    
    print("\né–‹å§‹ç”Ÿæˆæƒ…æ„Ÿåƒè€ƒéŸ³è¨Š...")
    
    for emotion, text in emotion_texts.items():
        output_path = emotion_dir / f"{emotion}.wav"
        
        print(f"\nç”Ÿæˆ {emotion} æƒ…æ„ŸéŸ³è¨Š...")
        print(f"  æ–‡æœ¬: {text}")
        
        try:
            # ç”ŸæˆéŸ³è¨Š
            wav = tts.tts(text=text, language="zh-cn")
            
            # å„²å­˜
            tts.synthesizer.save_wav(wav, str(output_path))
            print(f"  âœ“ å·²å„²å­˜è‡³: {output_path}")
            
        except Exception as e:
            print(f"  âœ— ç”Ÿæˆå¤±æ•—: {e}")
    
    print("\nå®Œæˆï¼è«‹æª¢æŸ¥ resource/emotions/ ç›®éŒ„")
    print("æ³¨æ„: è‡ªå‹•ç”Ÿæˆçš„éŸ³è¨Šå¯èƒ½éœ€è¦æ‰‹å‹•èª¿æ•´æˆ–ä½¿ç”¨çœŸäººéŒ„éŸ³æ›¿æ›")


if __name__ == "__main__":
    print("\nğŸ­ TTS æƒ…æ„Ÿæ§åˆ¶æ¼”ç¤º\n")
    
    # é¸æ“‡è¦åŸ·è¡Œçš„æ¼”ç¤º
    print("è«‹é¸æ“‡æ¼”ç¤º:")
    print("1. åŸºæœ¬æƒ…æ„Ÿæ§åˆ¶")
    print("2. è‡ªå‹•æƒ…æ„Ÿæª¢æ¸¬")
    print("3. å‰µå»ºæƒ…æ„Ÿåƒè€ƒéŸ³è¨Š")
    print("4. å…¨éƒ¨åŸ·è¡Œ")
    
    choice = input("\nè«‹è¼¸å…¥é¸é … (1-4): ").strip()
    
    if choice == "1":
        demo_basic_emotion_control()
    elif choice == "2":
        demo_emotion_detection()
    elif choice == "3":
        demo_create_emotion_audio()
    elif choice == "4":
        demo_basic_emotion_control()
        demo_emotion_detection()
        demo_create_emotion_audio()
    else:
        print("ç„¡æ•ˆçš„é¸é …")
    
    print("\nâœ“ æ¼”ç¤ºå®Œæˆï¼")
