"""
å±•ç¤ºæµå¼ Voice Agent èˆ‡å‚³çµ± Voice Agent çš„æ•ˆèƒ½å·®ç•°ã€‚

é€™å€‹ç¯„ä¾‹æœƒæ¯”è¼ƒï¼š
1. å‚³çµ±æ¨¡å¼ï¼šç­‰å¾…å®Œæ•´ LLM å›æ‡‰å¾Œæ‰é–‹å§‹ TTS
2. æµå¼æ¨¡å¼ï¼šLLM æ¯ç”Ÿæˆä¸€å¥å°±ç«‹å³ TTS
"""

import os
import time
import numpy as np
import soundfile as sf
from dotenv import load_dotenv

from modules.stt import WhisperSTT
from modules.tts import CoquiTTS
from modules.llm import OllamaLLM
from modules.agent import VoiceAgent
from modules.streaming_agent import StreamingVoiceAgent

load_dotenv()


def demo_traditional_mode():
    """å‚³çµ±æ¨¡å¼ï¼šç­‰å¾…å®Œæ•´å›æ‡‰ã€‚"""
    print("\n" + "="*60)
    print("ğŸ“Š å‚³çµ±æ¨¡å¼æ¸¬è©¦")
    print("="*60)
    
    # åˆå§‹åŒ–
    stt = WhisperSTT(model_size="medium", device="cuda")
    llm = OllamaLLM(api_url=os.getenv("LLM_API_URL", "http://localhost:11434"))
    tts = CoquiTTS(device="cuda")
    
    agent = VoiceAgent(stt, llm, tts)
    
    # æ¸¬è©¦å•é¡Œï¼ˆæœƒç”¢ç”Ÿè¼ƒé•·å›æ‡‰ï¼‰
    test_text = "è«‹è©³ç´°è§£é‡‹ä»€éº¼æ˜¯æ·±åº¦å­¸ç¿’ï¼ŒåŒ…æ‹¬å®ƒçš„æ­·å²ã€åŸç†å’Œæ‡‰ç”¨ã€‚"
    
    print(f"å•é¡Œï¼š{test_text}")
    print("\né–‹å§‹è™•ç†...")
    start_time = time.time()
    
    # è™•ç†ï¼ˆæœƒç­‰å¾…å®Œæ•´çš„ LLM + TTSï¼‰
    tts_result = agent.process_text(test_text)
    
    end_time = time.time()
    elapsed = end_time - start_time
    
    print(f"\nâœ… å®Œæˆï¼")
    print(f"â±ï¸  ç¸½è€—æ™‚ï¼š{elapsed:.2f} ç§’")
    print(f"ğŸ”Š éŸ³è¨Šé•·åº¦ï¼š{len(tts_result.audio) / tts_result.sample_rate:.2f} ç§’")
    print(f"âš ï¸  ä½¿ç”¨è€…ç­‰å¾…æ™‚é–“ï¼š{elapsed:.2f} ç§’ï¼ˆæ‰é–‹å§‹è½åˆ°ç¬¬ä¸€å€‹å­—ï¼‰")
    
    # å„²å­˜çµæœ
    sf.write("traditional_output.wav", tts_result.audio, tts_result.sample_rate)
    print(f"ğŸ’¾ å·²å„²å­˜è‡³ traditional_output.wav")
    
    return elapsed


def demo_streaming_mode():
    """æµå¼æ¨¡å¼ï¼šå³æ™‚å›æ‡‰ã€‚"""
    print("\n" + "="*60)
    print("âš¡ æµå¼æ¨¡å¼æ¸¬è©¦")
    print("="*60)
    
    # åˆå§‹åŒ–
    stt = WhisperSTT(model_size="medium", device="cuda")
    llm = OllamaLLM(api_url=os.getenv("LLM_API_URL", "http://localhost:11434"))
    tts = CoquiTTS(device="cuda")
    
    agent = StreamingVoiceAgent(
        stt, llm, tts,
        sentence_delimiters=r'[ã€‚ï¼ï¼Ÿ\.!?;ï¼›\n]',
        min_sentence_length=5
    )
    
    # ç›¸åŒçš„æ¸¬è©¦å•é¡Œ
    test_text = "è«‹è©³ç´°è§£é‡‹ä»€éº¼æ˜¯æ·±åº¦å­¸ç¿’ï¼ŒåŒ…æ‹¬å®ƒçš„æ­·å²ã€åŸç†å’Œæ‡‰ç”¨ã€‚"
    
    print(f"å•é¡Œï¼š{test_text}")
    print("\né–‹å§‹è™•ç†...")
    start_time = time.time()
    first_audio_time = None
    
    all_audio = []
    sentence_count = 0
    
    # æµå¼è™•ç†
    for tts_result, sentence in agent.process_text_stream(test_text):
        sentence_count += 1
        current_time = time.time()
        
        # è¨˜éŒ„ç¬¬ä¸€å€‹éŸ³è¨Šç‰‡æ®µçš„æ™‚é–“
        if first_audio_time is None:
            first_audio_time = current_time
            time_to_first_audio = first_audio_time - start_time
            print(f"\nğŸ¯ ç¬¬ä¸€å€‹å¥å­éŸ³è¨Šå·²ç”Ÿæˆï¼")
            print(f"â±ï¸  æ™‚é–“ï¼š{time_to_first_audio:.2f} ç§’")
            print(f"ğŸ“ å¥å­ï¼š{sentence[:50]}...")
        
        all_audio.append(tts_result.audio)
        elapsed = current_time - start_time
        print(f"   [{sentence_count}] +{elapsed:.2f}s: {sentence[:50]}...")
    
    end_time = time.time()
    total_elapsed = end_time - start_time
    
    # åˆä½µæ‰€æœ‰éŸ³è¨Š
    combined_audio = np.concatenate(all_audio)
    
    print(f"\nâœ… å®Œæˆï¼")
    print(f"â±ï¸  ç¸½è€—æ™‚ï¼š{total_elapsed:.2f} ç§’")
    print(f"ğŸ¯ é¦–æ¬¡å›æ‡‰ï¼š{time_to_first_audio:.2f} ç§’")
    print(f"ğŸ“Š å¥å­æ•¸é‡ï¼š{sentence_count}")
    print(f"ğŸ”Š ç¸½éŸ³è¨Šé•·åº¦ï¼š{len(combined_audio) / tts_result.sample_rate:.2f} ç§’")
    print(f"âœ¨ ä½¿ç”¨è€…é«”é©—ï¼š{time_to_first_audio:.2f} ç§’å¾Œå°±é–‹å§‹è½åˆ°å›æ‡‰")
    
    # å„²å­˜çµæœ
    sf.write("streaming_output.wav", combined_audio, tts_result.sample_rate)
    print(f"ğŸ’¾ å·²å„²å­˜è‡³ streaming_output.wav")
    
    return time_to_first_audio, total_elapsed


def demo_comparison():
    """æ¯”è¼ƒå…©ç¨®æ¨¡å¼çš„æ•ˆèƒ½ã€‚"""
    print("\n" + "ğŸ­ "*20)
    print("Voice Agent æ•ˆèƒ½æ¯”è¼ƒ")
    print("ğŸ­ "*20)
    
    # æ¸¬è©¦å‚³çµ±æ¨¡å¼
    traditional_time = demo_traditional_mode()
    
    # ç­‰å¾…ä¸€ä¸‹
    time.sleep(2)
    
    # æ¸¬è©¦æµå¼æ¨¡å¼
    streaming_first_time, streaming_total_time = demo_streaming_mode()
    
    # é¡¯ç¤ºæ¯”è¼ƒçµæœ
    print("\n" + "="*60)
    print("ğŸ“Š æ•ˆèƒ½æ¯”è¼ƒç¸½çµ")
    print("="*60)
    print(f"å‚³çµ±æ¨¡å¼ - ä½¿ç”¨è€…ç­‰å¾…æ™‚é–“ï¼š{traditional_time:.2f} ç§’")
    print(f"æµå¼æ¨¡å¼ - é¦–æ¬¡å›æ‡‰æ™‚é–“ï¼š  {streaming_first_time:.2f} ç§’")
    print(f"æµå¼æ¨¡å¼ - ç¸½è™•ç†æ™‚é–“ï¼š    {streaming_total_time:.2f} ç§’")
    print("")
    improvement = ((traditional_time - streaming_first_time) / traditional_time) * 100
    print(f"ğŸ’¡ æµå¼æ¨¡å¼å°‡é¦–æ¬¡å›æ‡‰æ™‚é–“æ¸›å°‘äº† {improvement:.1f}%")
    print(f"âœ¨ ä½¿ç”¨è€…æ„ŸçŸ¥å»¶é²å¾ {traditional_time:.2f}s é™è‡³ {streaming_first_time:.2f}s")
    print("="*60)
    
    print("\nğŸ¯ çµè«–ï¼š")
    print("å‚³çµ±æ¨¡å¼ï¼šä½¿ç”¨è€…å¿…é ˆç­‰å¾…å®Œæ•´çš„ LLM ç”Ÿæˆ + TTS åˆæˆ")
    print("æµå¼æ¨¡å¼ï¼šä½¿ç”¨è€…åªéœ€ç­‰å¾…ç¬¬ä¸€å¥è©±çš„ç”Ÿæˆ + TTSï¼Œé«”é©—æ›´æµæš¢")
    print("\né€™å°±æ˜¯ ElevenLabs ç­‰æœå‹™èƒ½åšåˆ°å³æ™‚å›æ‡‰çš„ç§˜å¯†ï¼")


def demo_streaming_visualization():
    """è¦–è¦ºåŒ–æµå¼è™•ç†çš„éç¨‹ã€‚"""
    print("\n" + "="*60)
    print("ğŸ¬ æµå¼è™•ç†éç¨‹è¦–è¦ºåŒ–")
    print("="*60)
    
    # åˆå§‹åŒ–
    stt = WhisperSTT(model_size="medium", device="cuda")
    llm = OllamaLLM(api_url=os.getenv("LLM_API_URL", "http://localhost:11434"))
    tts = CoquiTTS(device="cuda")
    
    agent = StreamingVoiceAgent(stt, llm, tts)
    
    test_text = "ä»€éº¼æ˜¯äººå·¥æ™ºæ…§ï¼Ÿ"
    
    print(f"å•é¡Œï¼š{test_text}\n")
    print("æ™‚é–“è»¸ï¼š")
    print("-" * 60)
    
    start_time = time.time()
    
    for i, (tts_result, sentence) in enumerate(agent.process_text_stream(test_text), 1):
        elapsed = time.time() - start_time
        bar_length = int(elapsed * 10)  # è¦–è¦ºåŒ–æ™‚é–“
        bar = "â–ˆ" * bar_length
        
        print(f"[{elapsed:5.2f}s] {bar}")
        print(f"         å¥å­ {i}: {sentence}")
        print(f"         éŸ³è¨Š: {len(tts_result.audio)} æ¨£æœ¬")
        print()
    
    total_time = time.time() - start_time
    print("-" * 60)
    print(f"ç¸½æ™‚é–“ï¼š{total_time:.2f} ç§’")


if __name__ == "__main__":
    import sys
    
    print("\n" + "ğŸ™ï¸ "*20)
    print("æµå¼ Voice Agent æ•ˆèƒ½å±•ç¤º")
    print("ğŸ™ï¸ "*20)
    
    options = [
        ("å®Œæ•´æ¯”è¼ƒæ¸¬è©¦", demo_comparison),
        ("æµå¼æ¨¡å¼æ¸¬è©¦", demo_streaming_mode),
        ("å‚³çµ±æ¨¡å¼æ¸¬è©¦", demo_traditional_mode),
        ("æµå¼è™•ç†è¦–è¦ºåŒ–", demo_streaming_visualization),
    ]
    
    print("\nè«‹é¸æ“‡æ¸¬è©¦é …ç›®ï¼š")
    for i, (name, _) in enumerate(options, 1):
        print(f"{i}. {name}")
    
    print("\nè¼¸å…¥æ•¸å­— (1-4)ï¼Œæˆ–æŒ‰ Enter åŸ·è¡Œå®Œæ•´æ¯”è¼ƒæ¸¬è©¦: ", end="")
    choice = input().strip()
    
    if choice == "" or choice == "1":
        demo_comparison()
    elif choice.isdigit() and 1 <= int(choice) <= len(options):
        options[int(choice) - 1][1]()
    else:
        print("ç„¡æ•ˆçš„é¸æ“‡ã€‚")
