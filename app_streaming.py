import os
from typing import Tuple
import numpy as np
import gradio as gr

from fastrtc import Stream, ReplyOnPause
from fastrtc.utils import AdditionalOutputs
from dotenv import load_dotenv

# å°å…¥æ¨¡çµ„åŒ–çš„å…ƒä»¶
from modules.stt import WhisperSTT
from modules.tts import CoquiTTS
from modules.llm import OllamaLLM
from modules.streaming_agent import StreamingVoiceAgent

load_dotenv()

# ========== åˆå§‹åŒ–æ¨¡çµ„åŒ–å…ƒä»¶ ==========

# 1. åˆå§‹åŒ– STT (Speech-to-Text)
stt_engine = WhisperSTT(
    model_size=os.getenv("STT_MODEL_SIZE", "medium"),
    device=os.getenv("DEVICE", "cuda").lower(),
    beam_size=5,
    vad_filter=False,
)

# 2. åˆå§‹åŒ– LLM (Language Model)
llm_engine = OllamaLLM(
    api_url=os.getenv("LLM_API_URL"),
    model=os.getenv("LLM_MODEL"),
    default_system_prompt=os.getenv("LLM_SYSTEM_PROMPT"),
    timeout=int(os.getenv("LLM_TIMEOUT", "60")),
)

# 3. åˆå§‹åŒ– TTS (Text-to-Speech)
tts_engine = CoquiTTS(
    model_name=os.getenv("TTS_MODEL", "tts_models/multilingual/multi-dataset/xtts_v2"),
    device=os.getenv("DEVICE", "cuda").lower(),
)

# 4. å»ºç«‹æµå¼ Voice Agentï¼ˆé—œéµæ”¹è®Šï¼ï¼‰
voice_agent = StreamingVoiceAgent(
    stt_engine=stt_engine,
    llm_engine=llm_engine,
    tts_engine=tts_engine,
    enable_llm=True,
    sentence_delimiters=r'[ã€‚ï¼ï¼Ÿ\.!?;ï¼›\n]',  # å¥å­åˆ†éš”ç¬¦
    min_sentence_length=5,  # æœ€å°å¥å­é•·åº¦
)

# ========== FastRTC Handler (æµå¼ç‰ˆæœ¬) ==========

def echo(audio: Tuple[int, np.ndarray]):
    """
    æµå¼è™•ç†éŸ³è¨Šè¼¸å…¥ä¸¦å³æ™‚è¿”å›èªéŸ³å›æ‡‰ã€‚
    
    èˆ‡åŸç‰ˆå·®ç•°ï¼š
    - åŸç‰ˆï¼šç­‰å¾…å®Œæ•´çš„ LLM å›æ‡‰å¾Œæ‰é–‹å§‹ TTS
    - æµå¼ç‰ˆï¼šLLM æ¯ç”Ÿæˆä¸€å€‹å¥å­å°±ç«‹å³ TTSï¼Œå¤§å¹…æ¸›å°‘å»¶é²
    """
    print("Received audio chunk for streaming processing.")
    
    full_response_text = ""
    
    # ä½¿ç”¨æµå¼ VoiceAgent è™•ç†éŸ³è¨Š
    # é€™æœƒå³æ™‚ yield æ¯å€‹å¥å­çš„éŸ³è¨Šï¼Œè€Œéç­‰å¾…å…¨éƒ¨å®Œæˆ
    for tts_result, sentence in voice_agent.process_audio_stream(audio):
        full_response_text += sentence
        
        print(f"[Streaming] Yielding sentence: '{sentence[:50]}...'")
        
        # ç«‹å³è¿”å›é€™å€‹å¥å­çš„éŸ³è¨Šå’Œç›®å‰ç´¯ç©çš„æ–‡å­—
        yield tts_result.as_tuple(), AdditionalOutputs(full_response_text)
    
    # å¦‚æœæ²’æœ‰ç”Ÿæˆä»»ä½•å…§å®¹
    if not full_response_text:
        yield AdditionalOutputs("æœªåµæ¸¬åˆ°èªéŸ³å…§å®¹ã€‚")

# ========== Gradio UI è¨­å®š ==========

transcript_box = gr.Textbox(label="Response (Streaming)", lines=6)


def update_transcript(current_text: str, new_text: str):
    """æ›´æ–°è½‰éŒ„æ–‡å­—æ¡†ï¼ˆæœƒæŒçºŒæ›´æ–°é¡¯ç¤ºæµå¼ç”Ÿæˆçš„å…§å®¹ï¼‰ã€‚"""
    return new_text


# å»ºç«‹ FastRTC Stream
stream = Stream(
    handler=ReplyOnPause(echo),
    modality="audio",
    mode="send-receive",
    additional_outputs_handler=update_transcript,
    additional_outputs=[transcript_box],
)

if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸš€ æµå¼èªéŸ³åŠ©ç† - å³æ™‚å›æ‡‰æ¨¡å¼")
    print("="*60)
    print("ç‰¹è‰²ï¼š")
    print("âœ… LLM æµå¼ç”Ÿæˆï¼ˆé€å­—è¼¸å‡ºï¼‰")
    print("âœ… æ™ºèƒ½åˆ†å¥è™•ç†")
    print("âœ… å³æ™‚ TTS åˆæˆ")
    print("âœ… é‚Šç”Ÿæˆé‚Šæ’­æ”¾ï¼Œå¤§å¹…æ¸›å°‘å»¶é²")
    print("="*60 + "\n")
    
    stream.ui.launch()
